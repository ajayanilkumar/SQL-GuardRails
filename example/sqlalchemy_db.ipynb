{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Database Creation from 'SampleSuperstore.csv' ---\n",
      "Successfully read CSV file.\n",
      "Cleaned column names for database compatibility:\n",
      "['ship_mode', 'segment', 'country', 'city', 'state', 'postal_code', 'region', 'category', 'sub_category', 'sales', 'quantity', 'discount', 'profit']\n",
      "\n",
      "Writing data to table 'sales' in database 'superstore.db'...\n",
      "\n",
      "--- Success! ---\n",
      "Database 'superstore.db' and table 'sales' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = 'SampleSuperstore.csv'\n",
    "DATABASE_FILE_NAME = 'superstore.db'\n",
    "TABLE_NAME = 'sales'\n",
    "\n",
    "def clean_col_names(df):\n",
    "    \"\"\"\n",
    "    Cleans column names to be valid SQL identifiers.\n",
    "    - Converts to lowercase\n",
    "    - Replaces spaces and hyphens with underscores\n",
    "    - Removes any other non-alphanumeric characters (except underscores)\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "    new_cols = []\n",
    "    for col in cols:\n",
    "        new_col = col.lower()\n",
    "        new_col = new_col.replace(' ', '_').replace('-', '_')\n",
    "        new_col = re.sub(r'[^a-zA-Z0-9_]', '', new_col)\n",
    "        new_cols.append(new_col)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "def create_database():\n",
    "    \"\"\"\n",
    "    Reads data from a CSV file and loads it into a new SQLite database table.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Database Creation from '{CSV_FILE_PATH}' ---\")\n",
    "    \n",
    "    # --- 1. Read and Clean the CSV Data ---\n",
    "    try:\n",
    "        df = pd.read_csv(CSV_FILE_PATH, encoding='windows-1252')\n",
    "        # This dataset is known to have a non-standard encoding.\n",
    "        # 'windows-1252' or 'latin1' often works if 'utf-8' fails.\n",
    "        \n",
    "        print(\"Successfully read CSV file.\")\n",
    "        \n",
    "        # Clean column names for SQL compatibility\n",
    "        df = clean_col_names(df)\n",
    "        print(\"Cleaned column names for database compatibility:\")\n",
    "        print(df.columns.tolist())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{CSV_FILE_PATH}' was not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Create SQLAlchemy Engine and Write to DB ---\n",
    "    try:\n",
    "        # The connection string for a SQLite database is 'sqlite:///filename.db'\n",
    "        engine = create_engine(f'sqlite:///{DATABASE_FILE_NAME}', echo=False)\n",
    "        \n",
    "        print(f\"\\nWriting data to table '{TABLE_NAME}' in database '{DATABASE_FILE_NAME}'...\")\n",
    "        \n",
    "        # Use df.to_sql to create the table and insert the data.\n",
    "        # if_exists='replace': If the table already exists, drop it and create a new one.\n",
    "        # index=False: Do not write the DataFrame's index as a column.\n",
    "        df.to_sql(TABLE_NAME, con=engine, if_exists='replace', index=False)\n",
    "        \n",
    "        print(\"\\n--- Success! ---\")\n",
    "        print(f\"Database '{DATABASE_FILE_NAME}' and table '{TABLE_NAME}' created successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during database creation: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_database()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sql_rail import SQLRail\n",
    "from sql_rail.core.distance_metrics import LevenshteinDistance, JaroWinklerSimilarity, TokenSetRatio\n",
    "from sql_rail.utils.data_loader_utils import load_all_reference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_values_map = load_all_reference_data(\"/Users/anilrao/Documents/GitHub/SQL-GuardRails/example/reference_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_rail_instance = SQLRail(\n",
    "    distance_calculators=[\n",
    "        LevenshteinDistance(),\n",
    "        JaroWinklerSimilarity(),\n",
    "        TokenSetRatio(),\n",
    "    ],\n",
    "    preloaded_references=column_values_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sql_rail_instance.analyze_query(sql_query=\"SELECT SUM(sales) FROM sales WHERE product_name = 'Xerox'\", k=3)\n",
    "analysis_results = []\n",
    "for condition in result.analyzed_conditions:\n",
    "    suggestions_by_metric = {}\n",
    "    for metric_analysis in condition.analyses_by_metric:\n",
    "        suggestions = []\n",
    "        for suggestion in metric_analysis.suggestions:\n",
    "            suggestions.append({\n",
    "                \"suggested_value\": suggestion.suggested_value,\n",
    "                \"similarity_score\": suggestion.similarity_score\n",
    "            })\n",
    "        suggestions_by_metric[metric_analysis.metric_name] = suggestions\n",
    "    analysis_results.append({\n",
    "        \"column_name\": condition.column_name,\n",
    "        \"operator\": condition.operator,\n",
    "        \"raw_value_in_query\": condition.raw_value_in_query,\n",
    "        \"suggestions\": suggestions_by_metric\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'column_name': 'product_name',\n",
       "  'operator': '=',\n",
       "  'raw_value_in_query': \"'Xerox'\",\n",
       "  'suggestions': {'LevenshteinDistance': [{'suggested_value': 'Xerox 2',\n",
       "     'similarity_score': 0.7142857142857143},\n",
       "    {'suggested_value': 'Xerox 21', 'similarity_score': 0.625},\n",
       "    {'suggested_value': 'Xerox 22', 'similarity_score': 0.625}],\n",
       "   'JaroWinklerSimilarity': [{'suggested_value': 'Xerox 2',\n",
       "     'similarity_score': 0.9428571428571428},\n",
       "    {'suggested_value': 'Xerox 21', 'similarity_score': 0.925},\n",
       "    {'suggested_value': 'Xerox 22', 'similarity_score': 0.925}],\n",
       "   'TokenSetRatio': [{'suggested_value': 'Xerox 1967',\n",
       "     'similarity_score': 1.0},\n",
       "    {'suggested_value': 'Xerox 232', 'similarity_score': 1.0},\n",
       "    {'suggested_value': 'Xerox 1943', 'similarity_score': 1.0}]}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
